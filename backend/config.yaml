# Realtime Dialogue Bot 後端 API 配置文件
api:
  title: "Realtime Dialogue API"
  version: "1.0.0"
  host: "0.0.0.0"
  port: 8000
  cors:
    allow_origins: ["*"]  # 生產環境請改為具體的前端網址
    allow_credentials: true
    allow_methods: ["*"]
    allow_headers: ["*"]

# STT (語音轉文字) 配置
stt:
  enabled: true
  model: "large-v3-turbo"  # 使用本地下載的模型
  model_path: "./models"   # 指向 backend/models
  device: "cuda:0"  # 可選值: "cuda:0", "cuda:1", "cpu"
  language: "zh"
  
# TTS 配置 - 可選擇使用 breezy, vibe, index, 或 spark
tts:
  provider: "spark"  # 可選值: "breezy", "vibe", "index", "spark"
  device: "cuda:0"  # 可選值: "cuda:0", "cuda:1", "cpu"
  
  breezy:
    enabled: false
    model_path: "./models/BreezyVoice"  # 使用實際的本地路徑
    model_repo: "MediaTek-Research/BreezyVoice-300M"
    breezy_voice_path: "/app/BreezyVoice"
    device: "cuda:0"  # 可選值: "cuda:0", "cuda:1", "cpu"
  
  vibe:
    enabled: true
    model_path: "./models/VibeVoice"
    model_repo: "Alibaba-NLP/VibeVoice"
    device: "cuda:0"  # 可選值: "cuda:0", "cuda:1", "cpu"
  
  index:
    enabled: true
    model_dir: "./models/IndexTTS-1.5/"
    cfg_path: "./models/IndexTTS-1.5/config.yaml"
    device: "cuda:0"  # 可選值: "cuda:0", "cuda:1", "cpu"
    # 預設參考語者設定
    default_speaker:
      audio_path: "./voices/zh-Novem_man.wav"  # 使用 voices 目錄中的中文語者
    # 語音合成參數
    synthesis:
      max_text_length: 500  # 最大文字長度
      timeout: 300  # 超時秒數

  spark:
    enabled: true
    model_dir: "./models/Spark-TTS-0.5B"
    device_id: 0  # CUDA 設備 ID
    # 預設參考語者設定
    default_speaker:
      audio_path: "./voices/zh-Novem_man.wav"  # 預設語者音檔
    # 預設語音參數
    default_prompt_text: "欸這個很有趣耶，趕快跟我說一下吧"  # 預設提示文字
    gender: "male"  # 預設性別: male, female
    pitch: "moderate"  # 預設音調: very_low, low, moderate, high, very_high
    speed: "moderate"  # 預設語速: very_low, low, moderate, high, very_high
    # 語音合成參數
    synthesis:
      max_text_length: 500  # 最大文字長度
      timeout: 300  # 超時秒數

# LLM 聊天配置
chat:
  enabled: true
  model: "Qwen/Qwen2.5-1.5B"  # 使用本地模型
  model_path: "./models/models--Qwen--Qwen2.5-1.5B"  # 指向實際的模型路徑
  device: "cuda:0"  # LLM 使用 CUDA 0
  llm_tools_device: "cuda:0"  # llm_tools 專用設備參數
  max_length: 512
  temperature: 0.7
  top_p: 0.9
  do_sample: true
  # 如果要使用 llm_tools 的配置，可以設定：
  use_llm_tools: true  # 是否使用 llm_tools/configs/models.yaml
  llm_tools_config: "./llm_tools/configs/models.yaml"
  llm_tools_model: "Qwen2.5-32B-Instruct-GPTQ-Int4"  # llm_tools 中的模型名

# 檔案路徑配置
paths:
  uploads: "./uploads"
  outputs: "./outputs"
  voices: "./voices"
  models: "./models"
  temp: "./temp"

# 記錄配置
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "./logs/app.log"

# 其他設定
settings:
  max_file_size: 50  # MB
  allowed_audio_formats: [".wav", ".mp3", ".m4a", ".flac"]
  allowed_text_length: 1000  # 最大文字長度
